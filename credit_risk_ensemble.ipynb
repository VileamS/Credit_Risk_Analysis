{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings('ignore')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom collections import Counter",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom imblearn.metrics import classification_report_imbalanced",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# https://help.lendingclub.com/hc/en-us/articles/215488038-What-do-the-different-Note-statuses-mean-\n\ncolumns = [\n    \"loan_amnt\", \"int_rate\", \"installment\", \"home_ownership\",\n    \"annual_inc\", \"verification_status\", \"issue_d\", \"loan_status\",\n    \"pymnt_plan\", \"dti\", \"delinq_2yrs\", \"inq_last_6mths\",\n    \"open_acc\", \"pub_rec\", \"revol_bal\", \"total_acc\",\n    \"initial_list_status\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\",\n    \"total_pymnt_inv\", \"total_rec_prncp\", \"total_rec_int\", \"total_rec_late_fee\",\n    \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_amnt\", \"next_pymnt_d\",\n    \"collections_12_mths_ex_med\", \"policy_code\", \"application_type\", \"acc_now_delinq\",\n    \"tot_coll_amt\", \"tot_cur_bal\", \"open_acc_6m\", \"open_act_il\",\n    \"open_il_12m\", \"open_il_24m\", \"mths_since_rcnt_il\", \"total_bal_il\",\n    \"il_util\", \"open_rv_12m\", \"open_rv_24m\", \"max_bal_bc\",\n    \"all_util\", \"total_rev_hi_lim\", \"inq_fi\", \"total_cu_tl\",\n    \"inq_last_12m\", \"acc_open_past_24mths\", \"avg_cur_bal\", \"bc_open_to_buy\",\n    \"bc_util\", \"chargeoff_within_12_mths\", \"delinq_amnt\", \"mo_sin_old_il_acct\",\n    \"mo_sin_old_rev_tl_op\", \"mo_sin_rcnt_rev_tl_op\", \"mo_sin_rcnt_tl\", \"mort_acc\",\n    \"mths_since_recent_bc\", \"mths_since_recent_inq\", \"num_accts_ever_120_pd\", \"num_actv_bc_tl\",\n    \"num_actv_rev_tl\", \"num_bc_sats\", \"num_bc_tl\", \"num_il_tl\",\n    \"num_op_rev_tl\", \"num_rev_accts\", \"num_rev_tl_bal_gt_0\",\n    \"num_sats\", \"num_tl_120dpd_2m\", \"num_tl_30dpd\", \"num_tl_90g_dpd_24m\",\n    \"num_tl_op_past_12m\", \"pct_tl_nvr_dlq\", \"percent_bc_gt_75\", \"pub_rec_bankruptcies\",\n    \"tax_liens\", \"tot_hi_cred_lim\", \"total_bal_ex_mort\", \"total_bc_limit\",\n    \"total_il_high_credit_limit\", \"hardship_flag\", \"debt_settlement_flag\"\n]\n\ntarget = [\"loan_status\"]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Load the data\nfile_path = Path('LoanStats_2019Q1.csv')\ndf = pd.read_csv(file_path, skiprows=1)[:-2]\ndf = df.loc[:, columns].copy()\n\n# Drop the null columns where all values are null\ndf = df.dropna(axis='columns', how='all')\n\n# Drop the null rows\ndf = df.dropna()\n\n# Remove the `Issued` loan status\nissued_mask = df['loan_status'] != 'Issued'\ndf = df.loc[issued_mask]\n\n# convert interest rate to numerical\ndf['int_rate'] = df['int_rate'].str.replace('%', '')\ndf['int_rate'] = df['int_rate'].astype('float') / 100\n\n\n# Convert the target column values to low_risk and high_risk based on their values\nx = {'Current': 'low_risk'}   \ndf = df.replace(x)\n\nx = dict.fromkeys(['Late (31-120 days)', 'Late (16-30 days)', 'Default', 'In Grace Period'], 'high_risk')    \ndf = df.replace(x)\n\ndf.reset_index(inplace=True, drop=True)\n\ndf.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Create our features\nX = df.drop(\"loan_status\", axis=1)\n\nX = pd.get_dummies(X)\n\n# Create our target\ny = df[\"loan_status\"]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X.describe()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Check the balance of our target values\ny.value_counts()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Resample the training data with the BalancedRandomForestClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nrandom_forest = BalancedRandomForestClassifier(n_estimators = 100)\nrandom_forest = random_forest.fit(X_train, y_train)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Calculated the balanced accuracy score\nfrom sklearn.metrics import balanced_accuracy_score\ny_pred = random_forest.predict(X_test)\nbalanced_accuracy_score(y_test, y_pred)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Display the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, y_pred)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Print the imbalanced classification report\nfrom imblearn.metrics import classification_report_imbalanced\nprint(classification_report_imbalanced(y_test, y_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# List the features sorted in descending order by feature importance\nfeature_names = X.columns\nsorted(zip(random_forest.feature_importances_, feature_names), reverse=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Train the EasyEnsembleClassifier\nfrom imblearn.ensemble import EasyEnsembleClassifier\neasy = EasyEnsembleClassifier(n_estimators = 100,random_state=1)\neasy = easy.fit(X_train, y_train)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Calculated the balanced accuracy score\ny_pred = easy.predict(X_test)\nbalanced_accuracy_score(y_test, y_pred)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Display the confusion matrix\nconfusion_matrix(y_test, y_pred)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Print the imbalanced classification report\nprint(classification_report_imbalanced(y_test, y_pred))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}